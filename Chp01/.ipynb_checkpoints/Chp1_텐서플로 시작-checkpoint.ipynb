{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chp1. 텐서플로 시작\n",
    "\n",
    "- __발표자 : 정지원__\n",
    "- __발표일 : 2017. 11. 04(토)__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 다루는 내용\n",
    "> - 텐서플로 동작 방식\n",
    "> - 변수 및 텐서 선언\n",
    "> - 플레이스홀더 및 변수 사용\n",
    "> - 행렬 다루기\n",
    "> - 연산 선언\n",
    "> - 활성화 함수 구현\n",
    "> - 데이터 출처 사용\n",
    "> - 추가 자료\n",
    "\n",
    "텐서 플로는 독창적인 방식을 사용한다. 많은 업무 분야에서 활용. 영상 처리/음성 인식/언어 번역/건강관리 등 사용된다. 먼저 기본 동작방식부터 이해하고 나중에는 실무적 기법까지 다룬다.\n",
    "\n",
    "## 텐서플로 동작 방식\n",
    "\n",
    "처음에는 복잡해보일 수 있으나, 이유가 있다. 이러한 복잡한 방식 덕분에 알고리즘을 비교적 쉽게 개발할 수 있다.\n",
    "\n",
    "### 준비\n",
    "\n",
    "리눅스, 맥, 윈도우를 지원한다. 이 책의 코드는 리눅스에서 작성하고 실행했지만 어디서든 실행 가능하다.\n",
    "\n",
    "https://github.com/nfmcclure/tensorflow_cookbookTensorflow\n",
    "\n",
    "텐서플로의 핵심 코드는 대부분 C++로 작성돼 있지만, 이 책에서는 파이썬 라이브러리만을 다룬다. 파이썬 3.4 이상, 텐서플로 0.12를 기준으로 작성했다. (한국어판은 텐서플로 1.2 정식버전과의 호환성을 검토했다. - 옮긴이) 그래픽 카드를 사용하면 좋다. 4GB 이상의 메모리에, 테슬라 아키텍처 혹은 파스칼 아키텍처를 사용할 수 있다.(최근에는 Volta가 나왔다. - 지원)\n",
    "\n",
    "### 예제 구현\n",
    "\n",
    "일반적인 텐서플로 알고리즘 흐름은 다음과 같다.\n",
    "\n",
    "#1. 데이터셋 가져오기 또는 생성하기\n",
    "> 데이터 셋을 생성하거나 공개된 데이터셋을 활용한다.\n",
    "\n",
    "#2. 데이터 변환 및 정규화 \n",
    "> 기대하는 형태로 주어지지 않는 경우가 보통이기 때문에, 수용할 수 있는 형태로 변환한다.\n",
    "\n",
    "#3. 데이터셋을 학습셋, 테스트셋, 검증셋으로 분할\n",
    "\n",
    "#4. 알고리즘 매개변수 설정\n",
    "> 하이퍼파라미터 튜닝을 통해 모델을 수정해나간다. 보통 이런 값들은 한곳에 모아 초기화하는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "batch_size = 100\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. 변수 및 플레이스홀더 초기화 - 수정할 수 있는 값/없는 값을 구분할 줄 알아야 한다. 변수 및 플레이스홀더의 크기와 타입을 초기화 시점에 지정하여 알려주어야 한다. 대부분 float32 타입을 사용한다. 텐서플로는 float64, float16 타입도 지원한다. 더 많은 바이트를 사용하면 알고리즘이 느려지지만, 정확도는 올라간다. 예제 코드를 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_var = tf.constant(42)\n",
    "x_input = tf.placeholder(tf.float32, [None, input_size])\n",
    "y_input = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6. 모델 구조 정의\n",
    "> 데이터를 준비하고 변수 및 플레이스홀더를 초기화한 후 모델을 정의, 그래프 생성을 통해 이뤄진다. 텐서플로는 모델의 결과를 얻기 위해 특정 연산과 값을 변수 및 플레이스홀더에 지정해야 한다. 예제를 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.add(tf.mul(x_input, weight_matrix), b_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7. 비용 함수(loss function) 선언\n",
    "> 모델을 정의한 후 모델 결과를 평가할 수 있어야 한다. 예시를 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y_actual - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8. 모델 초기화 및 학습\n",
    "> 이제 준비가 됐으니, 그래프 인스턴스를 생성하고 플레이스홀더에 데이터를 투입해 학습을 해보자. 다음과 같이 초기화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as session:\n",
    "    ...\n",
    "    session.run(...)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 하기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session(graph=graph)\n",
    "session.run(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9. 모델 평가\n",
    "> 생성하고 얼마나 잘 됐는지 평가한다. 오버피팅과 언더피팅을 확인해본다. 나중에 더 자세히 말하겠다.\n",
    "\n",
    "#10. 하이퍼파라미터 튜닝\n",
    "> 많은 경우, 성능을 분석해 다시 돌아가서 조정한다. 이러한 과정을 반복하면서 validation set으로 평가한다.\n",
    "\n",
    "#11. 적용 및 새로운 결과 예측\n",
    "> 실제 만들어진 모델을 적용하는 단계\n",
    "\n",
    "### 예제 분석\n",
    "\n",
    "예측을 개선하기 위해서는 데이터, 변수, 플레이스홀더, 모델을 준비해야 한다. 계산 그래프를 통해 이런 작업을 진행한다. 계산 그래프는 병렬 계산이 가능한 비순환 방향성 그래프다. 최소화 하려는 비용 함수를 생성하면, 그래프는 변수 수정을 통해 비용 함수를 최소화 한다. 자동으로 계산되며, 과정을 기록해두기 때문에 어떻게 수정해야 할 지 알 수 있다.\n",
    "\n",
    "### 참고 사항\n",
    "\n",
    "- 공식 문서는 정말 도움이 된다.\n",
    "> https://www.tensorflow.org/api_docs/python/\n",
    "\n",
    "- 튜토리얼\n",
    "> https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 정의\n",
    "\n",
    "주로 사용하는 자료 구조가 텐서(tensor)다. 변수로 선언할 수도 있고, placeholder로 선언할 수도 있다.\n",
    "\n",
    "#1. 고정 텐서\n",
    "- 0으로 채워진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_tsr = tf.zeros([row_dim, col_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1으로 채워진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ones_tsr = tf.ones([row_dim, col_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 동일한 상수 값으로 채워진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filled_tsr = tf.fill([row_dim, col_dim], 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기존 상수를 이용하여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constant_tsr = tf.constant([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. 형태가 비슷한 텐서\n",
    "- numpy와 비슷하다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zeros_similar = tf.zeros_like(constant_tsr)\n",
    "ones_similar = tf.ones_like(constant_tsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. 순열 텐서\n",
    "\n",
    "- 구간을 지정하는 방식으로 선언한다. range()나 linspace()와 비슷하게 동작한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_tsr = tf.linspace(start=0., stop=1., num=3)\n",
    "# [0.0, 0.5, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "integer_seq_tsr = tf.range(start=6, limit=15, delta=3)\n",
    "# [6, 9, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. 랜덤 텐서\n",
    "- 균등 분포를 따루는 난수 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randunif_tsr = tf.random_uniform([row_dim, col_dim], minval=0, maxval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 균등 분포 임의 함수에서 minval은 지정한 구간에 들어가지만, maxval은 들어가지 않는다.(minval <= x < maxval)\n",
    "- 다음과 같이 하면 정규 분포를 따르는 임의 숫자들을 텐서로 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randnrom_tsr = tf.random_nromal([row_dim, col_dim], mean=0.0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규 분포 임의의 값을 생성하고 싶은 경우가 있는데, 다음은 지정한 평균에서 항상 표준편차 2배 이내의 값을 뽑아준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runcnorm_tsr = tf.truncated_nromal([row_dim, col_dim], mean=0.0, stddev=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배열 항목을 임의로 뒤섞는 경우."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_output = tf.random_shuffle(input_tensor)\n",
    "cropped_output = tf.random_crop(input_tensor, crop_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 세 가지 스펙트럼을 가진 이미지를 임의로 특정 크기(height, width, 3)로 잘라내는 작업을 하는 경우..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "croppred_image = tf.random_crop(my_image, [height/2, width/2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서 생성 방법을 정하고 나면 Variable() 함수를 이용해 텐서를 담을 변수도 함께 생성해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_var = tf.Variable(tf.zeros([row_dim, col_dim]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도 convert_to_tensor()를 이용하면 어떤 numpy array든 파이썬 리스트로 변환해 상수를 텐서로 바꿀 수 있다.\n",
    "\n",
    "## 플레이스홀더 및 변수 사용\n",
    "\n",
    "어떤 것을 변수로 할지.. 플레이스홀더로 할지를 잘 선택해야 한다.\n",
    "\n",
    "예제로 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_var = tf.Variable(tf.zeros([2,3]))\n",
    "sess = tf.Session()\n",
    "initialize_op = tf.global_variables_initializer()\n",
    "sess.run(initialize_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 작성한 후, 나중에 feed_dict 인자를 통해 플레이스홀더에 데이터를 투입한다.\n",
    "\n",
    "아래 예제는 x와 x를 그대로 반환하는 항등 연산 y를 정의한 예제이다.\n",
    "\n",
    "feed_dict에 들어 있는 플레이스홀더를 그대로 자체 참조로 반환하지 않는다는 점을 알아두자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "x = tf.placeholder(tf.float32, shape=[2,2])\n",
    "y = tf.identity(x)\n",
    "x_vals = np.random.rand(2,2)\n",
    "sess.run(y, feed_dict={x:x_vals})\n",
    "# sess.run(x, feed_dict={x: x_vals}) 를 사용하면 자체 참조 오류가 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성한 변수의 초기화 시점을 알려줘야 한다.\n",
    "\n",
    "초기화 가능 시점에 대한 정보를 갖고 있어야 한다. 변수에 initializer 메소드가 있지만, 보통은 global_variables_initializer()를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initializer_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 변수의 초기화 결과를 이용해 변수를 초기화하고자 한다면 다음과 같이 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "first_var = tf.Variable(tf.zeros([2,3]))\n",
    "sess.run(first_var.initializer)\n",
    "second_var = tf.Variable(tf.zeros_like(first_var)) # first_var 사용\n",
    "sess.run(second_var.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 행렬 다루기\n",
    "\n",
    "#1. 행렬 생성\n",
    "> 앞 절에서 배운 것처럼, zeros(), ones(), truncated_normal() 등을 사용하여 2차원 형태로 행렬을 만들 수 있다. diag()함수를 이용해 1차원 배열이나 리스트를 대각 행렬로 만드는 것도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_matrix = tf.diag([1.0, 1.0, 1.0])\n",
    "A = tf.truncated_normal([2,3])\n",
    "B = tf.fill([2,3], 5.0)\n",
    "C = tf.random_uniform([3,2])\n",
    "D = tf.convert_to_tensor(np.array([[1., 2., 3.], [-3., -7., -1.], [0., 5., -2.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(identity_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.63541377 -0.05692191 -1.759547  ]\n",
      " [-1.68747675 -0.60871142  0.20415045]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  5.  5.]\n",
      " [ 5.  5.  5.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74710584  0.63954699]\n",
      " [ 0.02584791  0.77335811]\n",
      " [ 0.54089284  0.7588284 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [-3. -7. -1.]\n",
      " [ 0.  5. -2.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. 더하기, 빼기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.58906746  6.77452803  4.07674932]\n",
      " [ 3.74631548  3.82036161  5.60962915]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(A+B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곱하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  5.  5.]\n",
      " [ 5.  5.  5.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.matmul(B, identity_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. matmul()는 곱하기 전에 행렬을 전치할 것인지 희소 행렬인지 인자를 통해 지정할 수 있다.\n",
    "#4. 행렬 인자를 다음과 같이 전치할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.76090741  0.22967494  0.6354624 ]\n",
      " [ 0.0121125   0.08801794  0.51779032]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.transpose(C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. 다시 초기화하면 다른 값이 나온다.\n",
    "\n",
    "#6. 다음과 같이 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-38.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.matrix_determinant(D)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 역행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5        -0.5        -0.5       ]\n",
      " [ 0.15789474  0.05263158  0.21052632]\n",
      " [ 0.39473684  0.13157895  0.02631579]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.matrix_inverse(D)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7. 숄레스키 분해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.cholesky(identity_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8. 아이겐 벨류, 아이겐 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-10.65907521,  -0.22750691,   2.88658212]), array([[ 0.21749542,  0.63250104, -0.74339638],\n",
      "       [ 0.84526515,  0.2587998 ,  0.46749277],\n",
      "       [-0.4880805 ,  0.73004459,  0.47834331]]))\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.self_adjoint_eig(D)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 행은 아이겐 벨류, 그 뒤가 아이겐 벡터다.\n",
    "\n",
    "## 연산 정의\n",
    "\n",
    "연산 사용법을 알아보자...\n",
    "\n",
    "#1. div()함수 및 연관된 변형 함수가 있다.\n",
    "\n",
    "#2. div() 함수의 반환 값 타입은 입력 값과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.div(3,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.truediv(3,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3.소수를 대상으로 정수 나눗셈, 반환값은 소수 타입이지만 정수로 반올림한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.floordiv(3.0, 4.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. mod() , 나눗셈의 나머지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.mod(22.0, 5.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. 텐서 외적은 cross(), 3차원 벡터여야만 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.cross([1., 0., 0.], [0., 1., 0.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6. 자주 사용하는 수학 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.abs() # 입력 텐서의 절댓값\n",
    "tf.cell() # 입력 텐서의 상한값\n",
    "tf.cos() # 입력 텐서의 cosine값\n",
    "tf.exp() # 입력 텐서의 밑이 e인 지수 값\n",
    "tf.floor() # 입력 텐서의 하한 값\n",
    "tf.inv() # 입력 텐서의 역수 값\n",
    "tf.log() # 입력 텐서의 자연 로그 값\n",
    "tf.maximum() # 두 텐서에 대한 원소 단위 최댓값\n",
    "tf.minimum() # 두 텐서에 대한 원소 단위 최솟값\n",
    "tf.neg() # 부호 반전 값\n",
    "tf.pow() # 첫 번째 텐서의 원소를 두번째 텐서의 해당 원소 값만큼 거듭제곱한 값\n",
    "tf.round() # 입력 텐서의 반올림 값\n",
    "tf.rsqrt() # 입력 텐서의 제곱근의 역수 값\n",
    "tf.sign() # 입력 텐서의 부호에 따라, -1/0/1 값을 반환\n",
    "tf.sin() # 입력 텐서의 sine값\n",
    "tf.sqrt() # 입력 텐서의 제곱근 값\n",
    "tf.square() # 입력 텐서의 제곱 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7. 특수한 수학 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.digamma() # lgamma()함수의 도함수인 프사이 함수\n",
    "tf.erf() # 원소 단위, 텐서의 가우스 오차 함수\n",
    "tf.erfc() # 텐서의 여오차 함수\n",
    "tf.igmma() # 하부 정규화 불완전 감마 함수\n",
    "tf.igmmac() # 상부 정규화 불완전 감마 함수\n",
    "tf.lbeta() # 베타 함수 절댓값의 자연로그 값\n",
    "tf.lgamma() # 감마 함수 절댓값의 자연로그 값\n",
    "tf.squared_difference() # 두 텐서 차의 제곱 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $3x^{2} - x + 10$을 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n"
     ]
    }
   ],
   "source": [
    "def custom_polynomial(value):\n",
    "    return(tf.subtract(3 * tf.square(value), value) + 10)\n",
    "print(sess.run(custom_polynomial(11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활성화 함수 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   3.  10.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.relu([-3., 3., 10.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. 선형 증가 부분에 상한을 설정하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  3.  6.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.relu6([-3., 3., 10.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. 시그모이드 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.26894143  0.5         0.7310586 ]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.sigmoid([-1., 0., 1.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. 하이퍼볼릭 탄젠트 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.76159418  0.          0.76159418]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.tanh([-1., 0., 1.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. softsign 함수 $\\frac{x}{abs(x)+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5  0.  -0.5]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.softsign([-1., 0., -1.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6. softplus(매끄러운 ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.31326166  0.69314718  0.31326166]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.softplus([-1., 0., -1.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7. 지수 선형 유닛(ELU), softplus와 비슷한데 하부 점근선이 0이 아니라 -1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.63212055  0.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf.nn.elu([-1., 0., 1.])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
