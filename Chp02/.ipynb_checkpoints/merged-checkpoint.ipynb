{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations on a Computational Graph\n",
    "\n",
    "We start by loading the necessary libraries and resetting the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a graph session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data to feed in the placeholder\n",
    "x_vals = np.array([1., 3., 5., 7., 9.])\n",
    "\n",
    "# Create the TensorFlow Placceholder\n",
    "x_data = tf.placeholder(tf.float32)\n",
    "\n",
    "# Constant for multilication\n",
    "m = tf.constant(3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We loop through the input values and print out the multiplication operation for each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "9.0\n",
      "15.0\n",
      "21.0\n",
      "27.0\n"
     ]
    }
   ],
   "source": [
    "# Multiplication\n",
    "prod = tf.multiply(x_data, m)\n",
    "for x_val in x_vals:\n",
    "    print(sess.run(prod, feed_dict={x_data: x_val}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output graph to Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all(key='summaries')\n",
    "if not os.path.exists('tensorboard_logs/'):\n",
    "    os.makedirs('tensorboard_logs/')\n",
    "\n",
    "my_writer = tf.summary.FileWriter('tensorboard_logs/', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Operations on a Graph](https://github.com/nfmcclure/tensorflow_cookbook/raw/master/02_TensorFlow_Way/images/01_Operations_on_a_Graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layering Nested Operations\n",
    "\n",
    "We start by loading the necessary libraries and resetting the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a graph session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Tensors, Constants, and Placeholders\n",
    "\n",
    "We start by creating an array to feed in to a placeholder (note the agreements on the dimensions).  We then declare some graph constants to use in the operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data to feed in\n",
    "my_array = np.array([[1., 3., 5., 7., 9.],\n",
    "                   [-2., 0., 2., 4., 6.],\n",
    "                   [-6., -3., 0., 3., 6.]])\n",
    "# Duplicate the array for having two inputs\n",
    "x_vals = np.array([my_array, my_array + 1])\n",
    "# Declare the placeholder\n",
    "x_data = tf.placeholder(tf.float32, shape=(3, 5))\n",
    "# Declare constants for operations\n",
    "m1 = tf.constant([[1.],[0.],[-1.],[2.],[4.]])\n",
    "m2 = tf.constant([[2.]])\n",
    "a1 = tf.constant([[10.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Operations\n",
    "\n",
    "We start with matrix multiplication (A[3x5] * m1[5x1]) = prod1[3x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1st Operation Layer = Multiplication\n",
    "prod1 = tf.matmul(x_data, m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second operation is multiplication of prod1[3x1] by m2[1x1], which results in prod2[3x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2nd Operation Layer = Multiplication\n",
    "prod2 = tf.matmul(prod1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third operation is matrix addition of prod2[3x1] to a1[1x1], This makes use of TensorFlow's broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3rd Operation Layer = Addition\n",
    "add1 = tf.add(prod2, a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and Print Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 102.]\n",
      " [  66.]\n",
      " [  58.]]\n",
      "[[ 114.]\n",
      " [  78.]\n",
      " [  70.]]\n"
     ]
    }
   ],
   "source": [
    "for x_val in x_vals:\n",
    "    print(sess.run(add1, feed_dict={x_data: x_val}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Format Tensorboard outputs for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all(key='summaries')\n",
    "\n",
    "if not os.path.exists('tensorboard_logs/'):\n",
    "    os.makedirs('tensorboard_logs/')\n",
    "\n",
    "my_writer = tf.summary.FileWriter('tensorboard_logs/', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![layering_nested_operations](https://github.com/nfmcclure/tensorflow_cookbook/raw/master/02_TensorFlow_Way/images/02_Multiple_Operations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Multiple Layers\n",
    "\n",
    "First we start with loading the necessary libraries and resetting the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Graph Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tensors\n",
    "\n",
    "Here we will create a small image of size 4x4 pixels and propagate it through multiple layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a small random 'image' of size 4x4\n",
    "x_shape = [1, 4, 4, 1]\n",
    "x_val = np.random.uniform(size=x_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Data Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape=x_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Layer: Moving Window (Convolution)\n",
    "\n",
    "Our first layer will be a spatial moving window of size [2x2] with stride 2 (in both height and width directions)\n",
    "\n",
    "To make this a moving window average, the value of the filter will be all 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a layer that takes a spatial moving window average\n",
    "# Our window will be 2x2 with a stride of 2 for height and width\n",
    "# The filter value will be 0.25 because we want the average of the 2x2 window\n",
    "my_filter = tf.constant(0.25, shape=[2, 2, 1, 1])\n",
    "my_strides = [1, 2, 2, 1]\n",
    "mov_avg_layer= tf.nn.conv2d(x_data, my_filter, my_strides,\n",
    "                            padding='SAME', name='Moving_Avg_Window')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Layer: Custom\n",
    "\n",
    "Our second layer will be a custom layer.  Given an input, x, this layer flattens out x and computes sigmoid(Ax+b).  Here, A and b will be predetermined constants.\n",
    "\n",
    "We then add the custom layer to the graph under the name 'Custom_Layer'.  This is for visualizing the graph in Tensorboard later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a custom layer which will be sigmoid(Ax+b) where\n",
    "# x is a 2x2 matrix and A and b are 2x2 matrices\n",
    "def custom_layer(input_matrix):\n",
    "    input_matrix_sqeezed = tf.squeeze(input_matrix)\n",
    "    A = tf.constant([[1., 2.], [-1., 3.]])\n",
    "    b = tf.constant(1., shape=[2, 2])\n",
    "    temp1 = tf.matmul(A, input_matrix_sqeezed)\n",
    "    temp = tf.add(temp1, b) # Ax + b\n",
    "    return(tf.sigmoid(temp))\n",
    "\n",
    "# Add custom layer to graph\n",
    "with tf.name_scope('Custom_Layer') as scope:\n",
    "    custom_layer1 = custom_layer(mov_avg_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Output\n",
    "\n",
    "The output should be an array that is 2x2, but size (1,2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.39856768]\n",
      "   [ 0.85437918]]\n",
      "\n",
      "  [[ 0.2236276 ]\n",
      "   [ 0.35883212]]]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(mov_avg_layer, feed_dict={x_data: x_val}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After custom operation, size is now 2x2 (squeezed out size 1 dims), see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8636359   0.92904055]\n",
      " [ 0.78113878  0.77243596]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(custom_layer1, feed_dict={x_data: x_val}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save summaries for viewing in Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all(key='summaries')\n",
    "\n",
    "if not os.path.exists('tensorboard_logs/'):\n",
    "    os.makedirs('tensorboard_logs/')\n",
    "\n",
    "my_writer = tf.summary.FileWriter('tensorboard_logs/', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multiple_layers_tensorboard](https://github.com/nfmcclure/tensorflow_cookbook/raw/master/02_TensorFlow_Way/images/03_Multiple_Layers.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "\n",
    "This python script illustrates the different loss functions for regression and classification.\n",
    "\n",
    "We start by loading the ncessary libraries and resetting the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Graph Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Predictions\n",
    "\n",
    "---------------------------------\n",
    "\n",
    "To start with our investigation of loss functions, we begin by looking at numerical loss functions.  To do so, we must create a sequence of predictions around a target.  For this exercise, we consider the target to be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Various Predicted X-values\n",
    "x_vals = tf.linspace(-1., 1., 500)\n",
    "\n",
    "# Create our target of zero\n",
    "target = tf.constant(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Loss\n",
    "\n",
    "The L2 loss is one of the most common regression loss functions.  Here we show how to create it in TensorFlow and we evaluate it for plotting later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 loss\n",
    "# L = (pred - actual)^2\n",
    "l2_y_vals = tf.square(target - x_vals)\n",
    "l2_y_out = sess.run(l2_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 Loss\n",
    "\n",
    "An alternative loss function to consider is the L1 loss. This is very similar to L2 except that we take the `absolute value` of the difference instead of squaring it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L1 loss\n",
    "# L = abs(pred - actual)\n",
    "l1_y_vals = tf.abs(target - x_vals)\n",
    "l1_y_out = sess.run(l1_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-Huber Loss\n",
    "\n",
    "The psuedo-huber loss function is a smooth approximation to the L1 loss as the (predicted - target) values get larger.  When the predicted values are close to the target, the pseudo-huber loss behaves similar to the L2 loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L = delta^2 * (sqrt(1 + ((pred - actual)/delta)^2) - 1)\n",
    "\n",
    "# Pseudo-Huber with delta = 0.25\n",
    "delta1 = tf.constant(0.25)\n",
    "phuber1_y_vals = tf.multiply(tf.square(delta1), tf.sqrt(1. + tf.square((target - x_vals)/delta1)) - 1.)\n",
    "phuber1_y_out = sess.run(phuber1_y_vals)\n",
    "\n",
    "# Pseudo-Huber with delta = 5\n",
    "delta2 = tf.constant(5.)\n",
    "phuber2_y_vals = tf.multiply(tf.square(delta2), tf.sqrt(1. + tf.square((target - x_vals)/delta2)) - 1.)\n",
    "phuber2_y_out = sess.run(phuber2_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Regression Losses\n",
    "\n",
    "Here we use Matplotlib to plot the L1, L2, and Pseudo-Huber Losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKredAALuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb9e59569b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_array = sess.run(x_vals)\n",
    "plt.plot(x_array, l2_y_out, 'b-', label='L2 Loss')\n",
    "plt.plot(x_array, l1_y_out, 'r--', label='L1 Loss')\n",
    "plt.plot(x_array, phuber1_y_out, 'k-.', label='P-Huber Loss (0.25)')\n",
    "plt.plot(x_array, phuber2_y_out, 'g:', label='P-Huber Loss (5.0)')\n",
    "plt.ylim(-0.2, 0.4)\n",
    "plt.legend(loc='lower right', prop={'size': 11})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Predictions\n",
    "\n",
    "-------------------------------\n",
    "\n",
    "We now consider categorical loss functions.  Here, the predictions will be around the target of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Various predicted X values\n",
    "x_vals = tf.linspace(-3., 5., 500)\n",
    "\n",
    "# Target of 1.0\n",
    "target = tf.constant(1.)\n",
    "targets = tf.fill([500,], 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge Loss\n",
    "\n",
    "The hinge loss is useful for categorical predictions.  Here is is the `max(0, 1-(pred*actual))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hinge loss\n",
    "# Use for predicting binary (-1, 1) classes\n",
    "# L = max(0, 1 - (pred * actual))\n",
    "hinge_y_vals = tf.maximum(0., 1. - tf.multiply(target, x_vals))\n",
    "hinge_y_out = sess.run(hinge_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy Loss\n",
    "\n",
    "The cross entropy loss is a very popular way to measure the loss between categorical targets and output model logits.  You can read about the details more here: https://en.wikipedia.org/wiki/Cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross entropy loss\n",
    "# L = -actual * (log(pred)) - (1-actual)(log(1-pred))\n",
    "xentropy_y_vals = - tf.multiply(target, tf.log(x_vals)) - tf.multiply((1. - target), tf.log(1. - x_vals))\n",
    "xentropy_y_out = sess.run(xentropy_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Entropy Loss\n",
    "\n",
    "TensorFlow also has a sigmoid-entropy loss function.  This is very similar to the above cross-entropy function except that we take the sigmoid of the predictions in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = -actual * (log(sigmoid(pred))) - (1-actual)(log(1-sigmoid(pred)))\n",
    "# or\n",
    "# L = max(actual, 0) - actual * pred + log(1 + exp(-abs(actual)))\n",
    "x_val_input = tf.expand_dims(x_vals, 1)\n",
    "target_input = tf.expand_dims(targets, 1)\n",
    "xentropy_sigmoid_y_vals = tf.nn.softmax_cross_entropy_with_logits(logits=x_val_input, labels=target_input)\n",
    "xentropy_sigmoid_y_out = sess.run(xentropy_sigmoid_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted (Softmax) Cross Entropy Loss\n",
    "\n",
    "Tensorflow also has a similar function to the `sigmoid cross entropy` loss function above, but we take the softmax of the actuals and weight the predicted output instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weighted (softmax) cross entropy loss\n",
    "# L = -actual * (log(pred)) * weights - (1-actual)(log(1-pred))\n",
    "# or\n",
    "# L = (1 - pred) * actual + (1 + (weights - 1) * pred) * log(1 + exp(-actual))\n",
    "weight = tf.constant(0.5)\n",
    "xentropy_weighted_y_vals = tf.nn.weighted_cross_entropy_with_logits(x_vals, targets, weight)\n",
    "xentropy_weighted_y_out = sess.run(xentropy_weighted_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Categorical Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb9e4356e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the output\n",
    "x_array = sess.run(x_vals)\n",
    "plt.plot(x_array, hinge_y_out, 'b-', label='Hinge Loss')\n",
    "plt.plot(x_array, xentropy_y_out, 'r--', label='Cross Entropy Loss')\n",
    "plt.plot(x_array, xentropy_sigmoid_y_out, 'k-.', label='Cross Entropy Sigmoid Loss')\n",
    "plt.plot(x_array, xentropy_weighted_y_out, 'g:', label='Weighted Cross Entropy Loss (x0.5)')\n",
    "plt.ylim(-1.5, 3)\n",
    "#plt.xlim(-1, 3)\n",
    "plt.legend(loc='lower right', prop={'size': 11})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax entropy and Sparse Entropy\n",
    "\n",
    "Since it is hard to graph mutliclass loss functions, we will show how to get the output instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.16012561]\n",
      "[ 0.00012564]\n"
     ]
    }
   ],
   "source": [
    "# Softmax entropy loss\n",
    "# L = -actual * (log(softmax(pred))) - (1-actual)(log(1-softmax(pred)))\n",
    "unscaled_logits = tf.constant([[1., -3., 10.]])\n",
    "target_dist = tf.constant([[0.1, 0.02, 0.88]])\n",
    "softmax_xentropy = tf.nn.softmax_cross_entropy_with_logits(logits=unscaled_logits,\n",
    "                                                           labels=target_dist)\n",
    "print(sess.run(softmax_xentropy))\n",
    "\n",
    "# Sparse entropy loss\n",
    "# Use when classes and targets have to be mutually exclusive\n",
    "# L = sum( -actual * log(pred) )\n",
    "unscaled_logits = tf.constant([[1., -3., 10.]])\n",
    "sparse_target_dist = tf.constant([2])\n",
    "sparse_xentropy =  tf.nn.sparse_softmax_cross_entropy_with_logits(logits=unscaled_logits,\n",
    "                                                                  labels=sparse_target_dist)\n",
    "print(sess.run(sparse_xentropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Back Propagation\n",
    "\n",
    "For this recipe, we will show how to do TWO separate examples, a regression example, and a classification example.\n",
    "\n",
    "To illustrate how to do back propagation with TensorFlow, we start by loading the necessary libraries and resetting the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Graph Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Regression Example\n",
    "\n",
    "------------------------------\n",
    "\n",
    "We create a regression example as follows.  The input data will be 100 random samples from a normal (mean of 1.0, stdev of 0.1).  The target will be 100 constant values of 10.0.\n",
    "\n",
    "We will fit the regression model:  `x_data * A = target_values`\n",
    "\n",
    "Theoretically, we know that A should be equal to 10.0.\n",
    "\n",
    "We start by creating the data and targets with their respective placholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10., 100)\n",
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the variable for our computational graph, `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(shape=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the model operation to the graph.  This is just multiplying the input data by A to get the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add operation to graph\n",
    "my_output = tf.multiply(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to specify the loss function.  This will allow TensorFlow to know how to change the model variables.  We will use the L2 loss function here.  Note: to use the L1 loss function, change `tf.square()` to `tf.abs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add L2 loss operation to graph\n",
    "loss = tf.square(my_output - y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we initialize all our variables.  For specificity here, this is initializing the variable `A` on our graph with a random standard normal number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create an optimizing operations.  Here we use the standard `GradientDescentOptimizer()`, and tell TensorFlow to minimize the loss.  Here we use a learning rate of `0.02`, but feel free to experiment around with this rate, and see the learning curve at the end.  However, note that learning rates that are too large will result in the algorithm not converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Regression Graph!\n",
    "\n",
    "Here we will run the regression computational graph for 100 iterations, printing out the A-value and loss every 25 iterations.  We should see the value of A get closer and closer to the true value of 10, as the loss goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #25 A = [ 5.40734911]\n",
      "Loss = [ 26.12220001]\n",
      "Step #50 A = [ 8.33076572]\n",
      "Loss = [ 7.52755737]\n",
      "Step #75 A = [ 9.41368389]\n",
      "Loss = [ 4.23305845]\n",
      "Step #100 A = [ 9.93231583]\n",
      "Loss = [ 1.10820949]\n"
     ]
    }
   ],
   "source": [
    "# Run Loop\n",
    "for i in range(100):\n",
    "    rand_index = np.random.choice(100)\n",
    "    rand_x = [x_vals[rand_index]]\n",
    "    rand_y = [y_vals[rand_index]]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%25==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Example\n",
    "\n",
    "--------------------\n",
    "\n",
    "For the classification example, we will create an x-sample made of two different normal distribution inputs, `Normal(mean = -1, sd = 1)` and `Normal(mean = 3, sd = 1)`.  For each of these the target will be the class `0` or `1` respectively.\n",
    "\n",
    "The model will fit the binary classification:  If `sigmoid(x+A) < 0.5` then predict class `0`, else class `1`.\n",
    "\n",
    "Theoretically, we know that `A` should take on the value of the negative average of the two means: `-(mean1 + mean2)/2`.\n",
    "\n",
    "We start by resetting the computational graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a graph session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate the data that we will feed into the graph.  Note that the `x_vals` are the combination of two separate normals, and the y_vals are the combination of two separate constants (two classes).\n",
    "\n",
    "We also create the relevant placeholders for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "x_vals = np.concatenate((np.random.normal(-1, 1, 50), np.random.normal(3, 1, 50)))\n",
    "y_vals = np.concatenate((np.repeat(0., 50), np.repeat(1., 50)))\n",
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the one model variable, used for classification.  We also set the initialization function, a random normal, to have a mean far from the expected theoretical value.\n",
    "\n",
    "- Initialized to be around 10.0\n",
    "- Theoretically around -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(mean=10, shape=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the model operation to the graph.  This will be the adding of the variable `A` to the data.  Note that the `sigmoid()` is left out of this operation, because we will use a loss function that has it built in.\n",
    "\n",
    "We also have to add the batch dimension to each of the target and input values to use the built in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add operation to graph\n",
    "# Want to create the operstion sigmoid(x + A)\n",
    "# Note, the sigmoid() part is in the loss function\n",
    "my_output = tf.add(x_data, A)\n",
    "\n",
    "# Now we have to add another dimension to each (batch size of 1)\n",
    "my_output_expanded = tf.expand_dims(my_output, 0)\n",
    "y_target_expanded = tf.expand_dims(y_target, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add classification loss (cross entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(my_output_expanded, y_target_expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we declare the optimizer function.  Here we will be using the standard gradient descent operator with a learning rate of `0.05`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "train_step = my_opt.minimize(xentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an operation to initialize the variables and then run that operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Classification Graph!\n",
    "\n",
    "Now we can loop through our classification graph and print the values of A and the loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #200 A = [ 4.98884058]\n",
      "Loss = [[  9.61972692e-05]]\n",
      "Step #400 A = [ 1.25237942]\n",
      "Loss = [[ 0.13927367]]\n",
      "Step #600 A = [-0.43401867]\n",
      "Loss = [[ 0.06842836]]\n",
      "Step #800 A = [-0.78914857]\n",
      "Loss = [[ 0.18796471]]\n",
      "Step #1000 A = [-1.01327193]\n",
      "Loss = [[ 0.03451081]]\n",
      "Step #1200 A = [-1.02339005]\n",
      "Loss = [[ 0.03584756]]\n",
      "Step #1400 A = [-0.94646472]\n",
      "Loss = [[ 0.03685168]]\n"
     ]
    }
   ],
   "source": [
    "# Run loop\n",
    "for i in range(1400):\n",
    "    rand_index = np.random.choice(100)\n",
    "    rand_x = [x_vals[rand_index]]\n",
    "    rand_y = [y_vals[rand_index]]\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%200==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(xentropy, feed_dict={x_data: rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also see how well we did at predicting the data by creating an accuracy function and evaluating them on the known targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending Accuracy = 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Predictions\n",
    "predictions = []\n",
    "for i in range(len(x_vals)):\n",
    "    x_val = [x_vals[i]]\n",
    "    prediction = sess.run(tf.round(tf.sigmoid(my_output)), feed_dict={x_data: x_val})\n",
    "    predictions.append(prediction[0])\n",
    "    \n",
    "accuracy = sum(x==y for x,y in zip(predictions, y_vals))/100.\n",
    "print('Ending Accuracy = ' + str(np.round(accuracy, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch and Stochastic Training\n",
    "\n",
    "This python function illustrates two different training methods: batch and stochastic training.  For each model, we will use a regression model that predicts one model variable.\n",
    "\n",
    "We start by loading the necessary libraries and resetting the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start a computational graph session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Training\n",
    "\n",
    "----------------------\n",
    "\n",
    "### Generate Data\n",
    "\n",
    "The data we will create is 100 random samples from a `Normal(mean = 1, sd = 0.1)`.  The target will be an array of size 100 filled with the constant 10.0.\n",
    "\n",
    "We also create the necessary placeholders in the graph for the data and target.  Note that we use a shape of `[1]` for stochastic training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10., 100)\n",
    "\n",
    "x_data = tf.placeholder(shape=[1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variables and Operations\n",
    "\n",
    "We create the one variable in the graph, `A`.  We then create the model operation, which is just the multiplication of the input data and `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(shape=[1]))\n",
    "\n",
    "# Add operation to graph\n",
    "my_output = tf.multiply(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "For this, we choose the L2 loss.  We can easily choose the L1 loss by replacing `tf.square()` with `tf.abs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add L2 loss operation to graph\n",
    "loss = tf.square(my_output - y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization and Initialization\n",
    "\n",
    "For the optimization function, we will choose the standard Gradient Descent Algorithm with a learning rate of `0.02`.  We also add and run a variable initialization operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "We run the training step for 100 iterations and print off the value of `A` and the loss every 5 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #5 A = [ 2.15584159]\n",
      "Loss = [ 59.26628113]\n",
      "Step #10 A = [ 3.6463747]\n",
      "Loss = [ 38.98156357]\n",
      "Step #15 A = [ 4.82094002]\n",
      "Loss = [ 22.86421394]\n",
      "Step #20 A = [ 5.77139997]\n",
      "Loss = [ 19.58551025]\n",
      "Step #25 A = [ 6.52262354]\n",
      "Loss = [ 9.57485962]\n",
      "Step #30 A = [ 7.12625837]\n",
      "Loss = [ 6.36455345]\n",
      "Step #35 A = [ 7.63606024]\n",
      "Loss = [ 2.55103087]\n",
      "Step #40 A = [ 7.93105412]\n",
      "Loss = [ 2.34990478]\n",
      "Step #45 A = [ 8.30565166]\n",
      "Loss = [ 2.08385348]\n",
      "Step #50 A = [ 8.55292988]\n",
      "Loss = [ 6.9521904]\n",
      "Step #55 A = [ 8.81163883]\n",
      "Loss = [ 1.32351923]\n",
      "Step #60 A = [ 8.95606041]\n",
      "Loss = [ 6.76757669]\n",
      "Step #65 A = [ 9.12868977]\n",
      "Loss = [ 0.61686873]\n",
      "Step #70 A = [ 9.18059349]\n",
      "Loss = [ 0.01681929]\n",
      "Step #75 A = [ 9.22375107]\n",
      "Loss = [ 0.00448726]\n",
      "Step #80 A = [ 9.28870773]\n",
      "Loss = [ 0.08788975]\n",
      "Step #85 A = [ 9.44317436]\n",
      "Loss = [ 0.01499911]\n",
      "Step #90 A = [ 9.61464977]\n",
      "Loss = [ 0.00621458]\n",
      "Step #95 A = [ 9.65019512]\n",
      "Loss = [ 0.32731441]\n",
      "Step #100 A = [ 9.64083195]\n",
      "Loss = [ 0.31338796]\n"
     ]
    }
   ],
   "source": [
    "loss_stochastic = []\n",
    "# Run Loop\n",
    "for i in range(100):\n",
    "    rand_index = np.random.choice(100)\n",
    "    rand_x = [x_vals[rand_index]]\n",
    "    rand_y = [y_vals[rand_index]]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%5==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "        print('Loss = ' + str(temp_loss))\n",
    "        loss_stochastic.append(temp_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Training\n",
    "\n",
    "------------------\n",
    "\n",
    "We start by resetting the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch Training:\n",
    "# Re-initialize graph\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Batch training, we need to declare our batch size. The larger the batch size, the smoother the convergence will be towards the optimal value.  But if the batch size is too large, the optimization algorithm may get stuck in a local minimum, where a more stochastic convergence may jump out.\n",
    "\n",
    "Here, the we may change the batch size from 1 to 100 to see the effects of the batch size on the convergence plots at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare batch size\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Data\n",
    "\n",
    "The data we will create is 100 random samples from a `Normal(mean = 1, sd = 0.1)`.  The target will be an array of size 100 filled with the constant 10.0.\n",
    "\n",
    "We also create the necessary placeholders in the graph for the data and target.\n",
    "\n",
    "Note that here, our placeholders have shape `[None, 1]`, where the batch size will take the place of the `None` dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10., 100)\n",
    "x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variables and Operations\n",
    "\n",
    "We create the one variable in the graph, `A`.  We then create the model operation, which is just the multiplication of the input data and `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Add operation to graph\n",
    "my_output = tf.matmul(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "For this, we choose the L2 loss.  We can easily choose the L1 loss by replacing `tf.square()` with `tf.abs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add L2 loss operation to graph\n",
    "loss = tf.reduce_mean(tf.square(my_output - y_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization and Initialization\n",
    "\n",
    "For the optimization function, we will choose the standard Gradient Descent Algorithm with a learning rate of `0.02`.  We also add and run a variable initialization operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "We run the training step for 100 iterations and print off the value of `A` and the loss every 5 iterations.\n",
    "\n",
    "Note that here we select a batch of data instead of just one data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #5 A = [[ 1.87009048]]\n",
      "Loss = 65.4902\n",
      "Step #10 A = [[ 3.36440945]]\n",
      "Loss = 45.8059\n",
      "Step #15 A = [[ 4.58703709]]\n",
      "Loss = 29.0102\n",
      "Step #20 A = [[ 5.57683086]]\n",
      "Loss = 19.0908\n",
      "Step #25 A = [[ 6.38111591]]\n",
      "Loss = 13.8178\n",
      "Step #30 A = [[ 7.03755045]]\n",
      "Loss = 10.0696\n",
      "Step #35 A = [[ 7.5764699]]\n",
      "Loss = 6.38239\n",
      "Step #40 A = [[ 8.01234055]]\n",
      "Loss = 5.45151\n",
      "Step #45 A = [[ 8.35609531]]\n",
      "Loss = 2.84672\n",
      "Step #50 A = [[ 8.64307308]]\n",
      "Loss = 2.26105\n",
      "Step #55 A = [[ 8.84179211]]\n",
      "Loss = 2.03782\n",
      "Step #60 A = [[ 9.0474844]]\n",
      "Loss = 1.74324\n",
      "Step #65 A = [[ 9.21524715]]\n",
      "Loss = 1.54201\n",
      "Step #70 A = [[ 9.32061958]]\n",
      "Loss = 1.09765\n",
      "Step #75 A = [[ 9.4463768]]\n",
      "Loss = 1.29265\n",
      "Step #80 A = [[ 9.53134918]]\n",
      "Loss = 0.934568\n",
      "Step #85 A = [[ 9.59794903]]\n",
      "Loss = 0.810933\n",
      "Step #90 A = [[ 9.66680145]]\n",
      "Loss = 1.40375\n",
      "Step #95 A = [[ 9.71764565]]\n",
      "Loss = 1.36738\n",
      "Step #100 A = [[ 9.73819923]]\n",
      "Loss = 0.717119\n"
     ]
    }
   ],
   "source": [
    "loss_batch = []\n",
    "# Run Loop\n",
    "for i in range(100):\n",
    "    rand_index = np.random.choice(100, size=batch_size)\n",
    "    rand_x = np.transpose([x_vals[rand_index]])\n",
    "    rand_y = np.transpose([y_vals[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%5==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "        print('Loss = ' + str(temp_loss))\n",
    "        loss_batch.append(temp_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Stochastic vs Batch Training\n",
    "\n",
    "Here is the matplotlib code to plot the loss for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4069cb710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, 100, 5), loss_stochastic, 'b-', label='Stochastic Loss')\n",
    "plt.plot(range(0, 100, 5), loss_batch, 'r--', label='Batch Loss, size=20')\n",
    "plt.legend(loc='upper right', prop={'size': 11})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Everything Together\n",
    "\n",
    "This file will perform binary classification on the iris dataset. We will only predict if a flower is I.setosa or not. \n",
    "\n",
    "We will create a simple binary classifier by creating a line and running everything through a sigmoid to get a binary predictor. The two features we will use are pedal length and pedal width.  We use these two features because we know that Iris setosa is separable by these two features.  We aim to find the line that separates it out.\n",
    "\n",
    "We will use batch training, but this can be easily adapted to stochastic training (i.e. set batch size equal to 1).\n",
    "\n",
    "We start by loading the necessary libraries and resetting the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Iris Data\n",
    "\n",
    "We load the data and mark the target if it is I. setosa or not.  The input data will be the 3rd and 4th features of the data set. (Petal Length and Petal Width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the iris data\n",
    "# iris.target = {0, 1, 2}, where '0' is setosa\n",
    "# iris.data ~ [sepal.width, sepal.length, pedal.width, pedal.length]\n",
    "iris = datasets.load_iris()\n",
    "binary_target = np.array([1. if x==0 else 0. for x in iris.target])\n",
    "iris_2d = np.array([[x[2], x[3]] for x in iris.data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the batch size to 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we start a computational graph session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "\n",
    "We declare the placeholders for the model.  Just to illustrate that we can feed in multiple x-features separately, we create two separate placeholders for the two Iris features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare placeholders\n",
    "x1_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "x2_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variables\n",
    "\n",
    "We are going to be doing a linear model, so we will need to create two variables, `A` (slope) and `b` (intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variables A and b\n",
    "A = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Operations\n",
    "\n",
    "A line can be defined as $x_{1}=A\\cdot x_{2} + b$. To create a linear separator, we would like to see which side of the line the data points fall. There are three cases:\n",
    "\n",
    "- A point exactly on the line will satisfy: $0 = x_{1} - (A\\cdot x_{2} + b)$\n",
    "- A point above the line satisfies: $0 > x_{1} - (A\\cdot x_{2} + b)$\n",
    "- A point below the line satisfies: $0 < x_{1} - (A\\cdot x_{2} + b)$\n",
    "\n",
    "We will make the output of this model:\n",
    "\n",
    "$$x_{1} - (A \\cdot x_{2} + b)$$\n",
    "\n",
    "Then the predictions will be the sign of that output:\n",
    "\n",
    "$$Prediction(x_{1},x_{2}) = sign(x_{1} - (A \\cdot x_{2} + b))$$\n",
    "\n",
    "So we add the corresponding operations to the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add model to graph:\n",
    "# x1 - A*x2 + b\n",
    "my_mult = tf.matmul(x2_data, A)\n",
    "my_add = tf.add(my_mult, b)\n",
    "my_output = tf.sub(x1_data, my_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "Since we are doing a categorical prediction (I.setosa or not), we will use the sigmoid cross entropy loss.  This is a function provided to us by TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add classification loss (cross entropy)\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(my_output, y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Function and Variable Initialization\n",
    "\n",
    "We use the standard Gradient Descent Optimization function with a learning rate of `0.05`.  We then add and run a variable initialization operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "train_step = my_opt.minimize(xentropy)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Classification\n",
    "\n",
    "We run the classification for 1000 iterations and output the values of `A`, `b`, and loss every 200 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #200 A = [[ 8.48966789]], b = [[-3.37898731]]\n",
      "Step #400 A = [[ 10.06670666]], b = [[-4.63564396]]\n",
      "Step #600 A = [[ 11.00876522]], b = [[-5.43504715]]\n",
      "Step #800 A = [[ 11.8202858]], b = [[-5.87730837]]\n",
      "Step #1000 A = [[ 12.35187435]], b = [[-6.31382132]]\n"
     ]
    }
   ],
   "source": [
    "# Run Loop\n",
    "for i in range(1000):\n",
    "    rand_index = np.random.choice(len(iris_2d), size=batch_size)\n",
    "    #rand_x = np.transpose([iris_2d[rand_index]])\n",
    "    rand_x = iris_2d[rand_index]\n",
    "    rand_x1 = np.array([[x[0]] for x in rand_x])\n",
    "    rand_x2 = np.array([[x[1]] for x in rand_x])\n",
    "    #rand_y = np.transpose([binary_target[rand_index]])\n",
    "    rand_y = np.array([[y] for y in binary_target[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x1_data: rand_x1, x2_data: rand_x2, y_target: rand_y})\n",
    "    if (i+1)%200==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)) + ', b = ' + str(sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results\n",
    "\n",
    "We pull out the slope and intercept and plot the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEhCAYAAABr1YsqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMIwcwxS7YRhGjmGK3TAMI8f4/2jTa4gSsC/2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa9c4752358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pull out slope/intercept\n",
    "[[slope]] = sess.run(A)\n",
    "[[intercept]] = sess.run(b)\n",
    "\n",
    "# Create fitted line\n",
    "x = np.linspace(0, 3, num=50)\n",
    "ablineValues = []\n",
    "for i in x:\n",
    "  ablineValues.append(slope*i+intercept)\n",
    "\n",
    "# Plot the fitted line over the data\n",
    "setosa_x = [a[1] for i,a in enumerate(iris_2d) if binary_target[i]==1]\n",
    "setosa_y = [a[0] for i,a in enumerate(iris_2d) if binary_target[i]==1]\n",
    "non_setosa_x = [a[1] for i,a in enumerate(iris_2d) if binary_target[i]==0]\n",
    "non_setosa_y = [a[0] for i,a in enumerate(iris_2d) if binary_target[i]==0]\n",
    "plt.plot(setosa_x, setosa_y, 'rx', ms=10, mew=2, label='setosa')\n",
    "plt.plot(non_setosa_x, non_setosa_y, 'ro', label='Non-setosa')\n",
    "plt.plot(x, ablineValues, 'b-')\n",
    "plt.xlim([0.0, 2.7])\n",
    "plt.ylim([0.0, 7.1])\n",
    "plt.suptitle('Linear Separator For I.setosa', fontsize=20)\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Models\n",
    "\n",
    "This code will implement two models.  The first is a simple regression model, we will show how to call the loss function, MSE during training, and output it after for test and training sets.\n",
    "\n",
    "The second model will be a simple classification model.  We will also show how to print percent classified for both the test and training sets.\n",
    "\n",
    "### Regression Model\n",
    "\n",
    "For the regression model we will generate 100 random samples from a Normal(mean=1, sd=0.1).  The target will be an array of size 100 filled with the target value of 10.0.\n",
    "\n",
    "We will fit the linear model $y=A \\cdot x$ (no y intercept).  The theoretical value of `A` is `10.0`.\n",
    "\n",
    "To start we load the necessary libraries and reset the computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a graph session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data for Regression\n",
    "\n",
    "Here we generate the data required for the regression.  We also specify the necessary placeholders.\n",
    "\n",
    "After we split the data into a 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10., 100)\n",
    "x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# Split data into train/test = 80%/20%\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variables and Operations\n",
    "\n",
    "We create the model variable `A` and the multiplication operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "# Add operation to graph\n",
    "my_output = tf.matmul(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimization Function, and Variable Initialization\n",
    "\n",
    "We use the L2 loss, and the standard Gradient Descent Optimization with a learning rate of 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add L2 loss operation to graph\n",
    "loss = tf.reduce_mean(tf.square(my_output - y_target))\n",
    "\n",
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Regression\n",
    "\n",
    "We iterate 100 times through the training step, selecting a random batch of data each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #25 A = [[ 6.47693586]]\n",
      "Loss = 12.0633\n",
      "Step #50 A = [[ 8.68510914]]\n",
      "Loss = 2.556\n",
      "Step #75 A = [[ 9.50503254]]\n",
      "Loss = 1.21711\n",
      "Step #100 A = [[ 9.77385426]]\n",
      "Loss = 1.04426\n"
     ]
    }
   ],
   "source": [
    "# Run Loop\n",
    "for i in range(100):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = np.transpose([x_vals_train[rand_index]])\n",
    "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%25==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Regression Model\n",
    "\n",
    "For the regression model evaluation, we will run the loss wih the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test:0.96\n",
      "MSE on train:1.16\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy (loss) on test set\n",
    "mse_test = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_test]), y_target: np.transpose([y_vals_test])})\n",
    "mse_train = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_train]), y_target: np.transpose([y_vals_train])})\n",
    "print('MSE on test:' + str(np.round(mse_test, 2)))\n",
    "print('MSE on train:' + str(np.round(mse_train, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Example\n",
    "\n",
    "For the classification example, we generate data as follows:\n",
    "\n",
    "The input data will be a sample of size 50 from a Normal(mean = -1, sd = 1) and a sample of 50 from a Normal(mean = 1, sd = 1).\n",
    "\n",
    "The target data will be 50 values of 0 and 50 values of 1.\n",
    "\n",
    "We fit the binary classification model:\n",
    "\n",
    "- If $sigmoid(x+A)<0.5$ Then we predict class 0\n",
    "- If $sigmoid(x+A)>=0.5$ Then we predict class 1\n",
    "\n",
    "Theoretically A should be\n",
    "\n",
    "$$ - \\frac{mean1 + mean2}{2} = 0$$\n",
    "\n",
    "We start by resetting the computational graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Classification Data and Targets\n",
    "\n",
    "We generate the classification data as described above.  Then we create the necessary placeholders.\n",
    "\n",
    "After, we split the data in a 80-20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "x_vals = np.concatenate((np.random.normal(-1, 1, 50), np.random.normal(2, 1, 50)))\n",
    "y_vals = np.concatenate((np.repeat(0., 50), np.repeat(1., 50)))\n",
    "x_data = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "\n",
    "# Split data into train/test = 80%/20%\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Variables and Operations\n",
    "\n",
    "We create the model variable, `A`, and the model operation, which is the adding of `A` to the input data.  Note that we do not put the `sigmoid()` function in here because it will be included in the loss function.  This also means that for prediction, we will need to include the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(mean=10, shape=[1]))\n",
    "\n",
    "# Add operation to graph\n",
    "# Want to create the operstion sigmoid(x + A)\n",
    "# Note, the sigmoid() part is in the loss function\n",
    "my_output = tf.add(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimization Function, and Variable Initialization\n",
    "\n",
    "The loss will be the sigmoid-cross-entropy.  We wrap that function in a `tf.reduce_mean()` so that we can reduce the sigmoid-cross-entropy over the whole batch.\n",
    "\n",
    "The optimization function we use is again the standard Gradient Descent Optimization with a learning rate of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add classification loss (cross entropy)\n",
    "xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(my_output, y_target))\n",
    "\n",
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "train_step = my_opt.minimize(xentropy)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Classification\n",
    "\n",
    "We iterate the classification training operation for 1800 iterations and print off the `A` values along with the loss every 200 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #200 A = [ 5.70815563]\n",
      "Loss = 2.20039\n",
      "Step #400 A = [ 1.35876882]\n",
      "Loss = 0.53517\n",
      "Step #600 A = [-0.13932848]\n",
      "Loss = 0.246674\n",
      "Step #800 A = [-0.50210857]\n",
      "Loss = 0.296652\n",
      "Step #1000 A = [-0.57548112]\n",
      "Loss = 0.308673\n",
      "Step #1200 A = [-0.55576968]\n",
      "Loss = 0.242491\n",
      "Step #1400 A = [-0.61009347]\n",
      "Loss = 0.269398\n",
      "Step #1600 A = [-0.60937202]\n",
      "Loss = 0.223748\n",
      "Step #1800 A = [-0.5841468]\n",
      "Loss = 0.245155\n"
     ]
    }
   ],
   "source": [
    "# Run loop\n",
    "for i in range(1800):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = [x_vals_train[rand_index]]\n",
    "    rand_y = [y_vals_train[rand_index]]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%200==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(xentropy, feed_dict={x_data: rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.95\n",
      "Accuracy on test set: 0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEKCAYAAAA7LB+5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VPW9//HXB1EBEwggiBtEUJaKlXpb61YZ0SpQF3p/\nXhEQpXrtldar/Kp4XSok9OdyXW5TrV3UgiLi1StK1eoVCw1utdqCIIIrhqBYBSGEsAXI5/fHOZlO\nkpnJZJnkJLyfj8c8MnPO93zP58yc+eQ737N8zd0REZHo6tDaAYiISHpK1CIiEadELSIScUrUIiIR\np0QtIhJxStQiIhGnRN2KzOzXZnZTa8eRCTP7k5ldmqW6DzezcjOz8HVvM3vZzDab2Z1mdoOZ3Z+N\ndYu0BUrUWWRmJWa2LUxCX5nZs2Z2aPV8d5/s7re0ZozVzGxfMyswsw/MbIuZrTazB82sb7bX7e5r\n3b2r/+Ok/h8CX7p7N3ef6u63ufsPsxmDmXUxswozey6b64kqMxtmZn81s61m9paZHZum7GAzW2hm\nZeH+MiZhXj8zqwr3+S3h3zbRGIkyJerscuB77t4VOBj4Erg32ys1s30asdg84GzgQqAbcCzwN+D0\nZgwtU/2Alc1RUXUrPQPnAzuAM83soOZYd6Ya+Xk15/r3BeYDs4G88O/vzaxjkrL7AL8HngG6A/8G\nzDGzIxOKOdDN3XPDf8CRaIy0ae6uR5YewCfAiITXo4D3El7PAmaEz4cDa4GfAF8AnwGTEsqOBpYA\nm4E1wPSEef2AKuDScF4x8BxwZa14lgHnJonzDGArcEiabfkTcGn4vD+wENhA8M9nDtA1oex/AJ8C\n5cAq4LRw+reAt8Jt+By4q1b8HcL3pBLYGS4/ApgOPJJQ/wnAa8AmYCkwvFac/w94Ndym/hl+VguB\nnwF/BX5Sa95hBP/IvgTWA/ckzLuc4J9KObACGBZOr0pcd4rP+rrwfXiYIEE+G67jq/D5IQnLdwdm\nhvvFV8BT4fR3CBoD1eU6hjF+vQH76XeBtbWmrQHOTFL2aKC81rQXgcJan+U+rf39a08PtahbiJl1\nAcYCf05TrA+QCxwC/Ctwn5l1C+dVABPdvRvwPeAKMzu31vKnAoOAswi+/BclrP/YsN7nk6z3dOBN\nd1+X6eYAt4bxDiFIZAXhegYCPwb+yYNfEmcBJeFyvwCKwm0YADyRUKcDuPsPgEeB//SgNbYocX7Y\ndfQcQdLrDlwLzDOzngl1XUTw/uUSJJz0GxN078TC9c4FLkmY1yFc3ydAX+BQ4L/Def8CTAMuCrf1\nXIIkGo83jT4EybkvQVdPB4JEfHg4bRtwX0L5OUBngve7N/DzcPpsYGJCue8B69x9eRjjJjPbGP5N\nfL7RzK4LlzkaWF4rvuXh9NqS/UIxYGjCawdKzKzUzGbW+mykEZSos2++mW0kaEWeAdyVpmwl8DN3\n3+PuLxAk50EA7v6yu78bPl9BkCyGJyzrBK3sHe6+k+Dn6ZFmNiCcfxHwuLvvTrLengQtu4y4+8fu\nvtDdd7v7VwRJozqWPcB+wFAz6+jupe7+ScL2HWlmPd19m7u/mek6E0wA/uDuL4axLCRoBY9OKPOQ\nu7/n7lXuvieDOi8Glrn7e8BjwNcS+miPJ+i2ui58byvd/fVw3mXAHe6+JIxltbuvDefV1+Wyh+Dz\n2uXuO919o7s/HT7fCtxG8I8XMzuY4B/ev7l7ebh/vBLWMwcYZWY54euLgEeqV+Lu3d29R/g38XkP\nd78jLJZDsH8m2kzwj66294AvzexaM+toZmcSfPZdwvkbCH459QP+Kazj0XreC6mHEnX2nefuPQiS\n178DL5tZ7xRlv3L3qoTX2wi+RJjZt81skZl9aWZlBH2DB9Za/tPqJ+5eSdBivSjspx1Hwhe49noJ\nklFGzKyXmT1mZp+GscypjsXdPwamELSwvzCzuWGigSCxDQLeM7O/mNn3Ml1ngn7ABWGLcKOZbQJO\nJmihVlubfNGUJhImE3f/HHiZf7SqDwfW1PpcSJj3cQPXVW29u++qfmFmnc3st+EB6DJgMZAXfnaH\nARvdvbx2JWG8rwH/J/z1NYqGJ8YKoGutaV2BLUnWtxsYQ3A843Pg/wKPE+577r7V3ZeE/yTXA1cS\n9Pvn1K5LMqdEnX0G4IGnCVpSpzSinkcJDvgc6u55wG+p22qr/XN7NkEL63Rgq7v/JUXdfwSON7ND\nMozlNoJ+yKFhLBclxuLu/+3u3yFIqgC3h9M/dvfx7t4LuAN40sw6Z7jOamuB2WGLsLp1mOvudyaU\nyfiWkGZ2InAUcIOZfW5mnxO0oseF3R5rgb7h82SxDEgyHYJ/sl0SXvepNb92jNeEcXwrfE9PrQ4x\nXE8PM6udTKtVd3/8C/B6mLyrt6/6zIvER/W068Ni7wJfr1Xn18Ppdbj7CnePuXsvdx9F8B6k+3Xk\n1P8LQ9JQom5BZnYeQb9kY85oyAE2ufsuMzseGF+7+toLuPsbBAn1blK3pqu7D14Cnjaz48xsHzPL\nMbN/M7NJSRbJJWiFlYd9xlPjQZgNNLPTzGw/gq6O7QT/nDCzCWZW/StgM8EXuLprItMv8hzgHDM7\n08w6mFknMxue7p+MmU03s0UpZk8CFhD0/R4bPo4BDiBonb5J0HK8PTyFb38zOylc9kHgWjM7LlzP\nADM7PJy3FBgfxjiSmt1UyeQSvFflZtaDsM8fwN3/DrwA/MrM8sIuh+8kLDsfOA64iiBpk7Bs9ZkX\niY/qabeHxYqBPWb272a2n5ldSfDZJH3PzOyY8H3oYmbXEvwTeiicd3y4D1jYN/0L4E/uXqd1LplT\nos6+Z8PWy2aCswouDvtCM5HY6voR8LOwnp8S/NxMVTbRbIIDPXPqWdf5BAcaHwfKCM4m+CeC1nbt\n+gvDeWUEZyfMS5i3P0ELej2wDugF3BjOGwm8a2blBP3aY8MumnTx1+DunwLnhXWuJzhYeC3/2JeT\n1XM4QfdADWa2P8F23+Pu6939y/BRQvC+XRJ2eZxD0NotJWjdXhDG8iRwCzA33KangR5h9VMIDi5u\nIuh2erqeTSsiaIFvAF6n7kHficBugj7iL4CrE96THQSfwRHAU/Wsp46wC2YMQXfPJoJ/XudVH8+w\n4IKjP9SK5XPg78BpwHcTunH6A/9LcBbMcoJTHms3KqSBzL3+74eZXU1wFB3gAXe/J6tRSbMxs4nA\n5e5+ar2F2ykzWwKc7u6bWjuWbDGzm4Gj3P3i1o5Fml+9LWozO5rgINA3gWEEPztT9ctJhFhwSuCP\nCPqz91ruflw7T9I9CL6je/Xn3J5l0vUxBHgjPG1oD8HR6O9nNyxpqvC0qS8JfqI+1srhSJaY2b8S\ndMn8wd3rdO9I+1Bv14eZDSY4WHEiwdVifwTecver0y4oIiLNos61/LW5+3tm9p8ECXoL8DbBQQ0R\nEWkBGR1MrLGA2S0E9wX4Ta3pGs5cRKSB3L3eU1MzOj3PzHqFf/sS9E8n7fP0CNy8JBuP6dOnt3oM\n2r69Y/umX3IJPn16jcf0Sy5pN9vX3j+/hj4yVW/XR2heeGR5F/Ajd699XwAREcmSjBK178Xn4IqI\ntDZdmZiBWCzW2iFklbavbdP2tX9K1Blo7zuKtq9t0/a1fw0+6yNlRWbeXHWJtJT8/HzWrKl3bAGR\nJunXrx8lJSV1ppsZnsFZH0rUslcLvyitHYa0c6n2s0wTtbo+REQiTolaRCTilKhFRCJOiVpEJOKU\nqEX2ch06dCA3N5ebb765tUNps4488kj2339/Lr44O+M2KFGLRFwsFqNHjx7s2rWr/sKNYGYsX76c\nn/3sZynLLFy4kCFDhpCTk8Ppp59OaWlpyrL5+fl06dKFrl270rVrV0aOHBmfN3nyZHJzc+PzOnXq\nRLdu3eLz33vvPU4//XTy8vIYOHAg8+fPr1H3gw8+yFFHHUXXrl0ZPXo0n38eH8eXzZs3M2nSJA46\n6CD69OlDYWFhjWVff/11vv3tb9O1a1eGDRvGa6/VvH33LbfcQr9+/cjLy2P8+PFUVFTE523atImx\nY8fSq1cvevfuzcSJE2vM/+ijj7jxxhvJmma8uYiLtDVR329LSkp8n3328Z49e/qTTz6ZlXWYmX/8\n8ccp52/YsMG7devm8+bN8507d/rUqVP9hBNOSFk+Pz/fFy1alNG6J02a5Jdddpm7u+/evdsHDhzo\nRUVFXlVV5YsWLfIDDjjAP/zwQ3d3Ly4u9t69e/uqVat8165dPnnyZB8+fHiNui644ALfsWOHl5SU\n+IABA/yhhx5yd/eNGzf6gQce6PPmzfOqqiqfM2eOd+/e3cvKytzd/aGHHvIhQ4b4Z5995lu3bvXz\nzjvPL7nkknjdkydP9rPOOssrKiq8vLzczzjjDL/mmmtqbEtBQYFPnDgx6Xam2s/C6fXn10wKZVRR\nxHd4kWTq22+nT5/uBAPm1nhMnz494/KpymZixowZfsopp/g111zjZ599dqPrSae+RH3//ff7ySef\nHH+9detW79y5s7///vtJy+fn5/vChQvrXW9FRYXn5ub6K6+84u7uK1as8Nzc3BplzjzzTJ82bZq7\nu1977bV+5ZVXxuetW7fOzcxXr17t7u4HHnig/+1vf4vPv/XWW/3UU091d/fnnnvOhw4dWqPugQMH\n+syZM93d/fzzz/e77rorPu/111/3Tp06+fbt293dfdSoUf7rX/86Pv++++7zkSNH1qgvm4laXR8i\nETZ79mwuuugixo8fz4svvsj69etTlv3xj39M9+7d6dGjR/xv9fNhw4Y1OoZ3332XY489Nv66S5cu\nDBgwgHfffTflMhMmTOCggw5i5MiRLF++PGmZefPm0bt3b0455RSApBeEuDsrVqyIP08sU1VVBRCf\nnzit+nmqZTOpu7Kykg8//BAI3ttnn32WsrIyNm3axLx58xg9enTK7W9uStQiEfXqq69SWlrKBRdc\nwHHHHceRRx7J3LlzU5a/77772LRpExs3boz/rX7+9ttvNzqOioqKGv3IAN26dWPLli1Jy8+dO5eS\nkhLWrFlDLBbjrLPOory8vE652bNn1zj4NnjwYHr37s1dd93F7t27WbBgAYsXL2bbtm0AjB49miee\neIIVK1awfft2ZsyYQYcOHeLzR44cye23305FRQUfffQRs2bNis876aSTWLduHY8//ji7d+/m4Ycf\n5uOPP47PHzVqFA8++CBr1qxh8+bN3HHHHQDx+ccddxyVlZX07NmTXr160bFjRyZPntzo97ShlKhF\n0igoKEj6U7SgoCDj8qnK1mf27NmceeaZdO/eHYBx48bx8MMPN3JLGi8nJ6dOoi0vLyc3Nzdp+RNP\nPJH999+fTp06cf3115OXl8crr7xSo8zatWtZvHhxjUTdsWNH5s+fz3PPPcfBBx/Mz3/+c8aOHcth\nhx0GwIgRIygsLOSf//mfOeKII+jfvz+5ubnx+ffccw+dOnXiqKOO4vvf/z7jx4+Pz+vRowe///3v\nufvuu+nTpw8LFizgu9/9bnz+pZdeyrhx44jFYhxzzDGMGDECID7//PPPZ9CgQWzdupXy8nL69+/P\nhAkTmvrWZi6T/pFMHqiPWtqgqO6327dv927dunlubq736dPH+/Tp4z169PAOHTr48uXLky5zxRVX\neE5Ojufm5tZ45OTk1OmfTdTQPuqKigrv0qVLyj7q2oYMGeLPPvtsjWm33HJLjQOBqZx00kl+//33\nJ533wQcfeE5OTvyAYG033nijjx8/Pum83bt3e79+/XzBggVJ57/44ot++OGHx1/n5OTUeN/ffvvt\nOv3prX4wEfi/wApgOfAosF+SMkkDEYmyqO63c+fO9Z49e/qnn37qX3zxRfwxfPjwOmcbNFV9iXr9\n+vWel5fnTz31lO/YscOvu+46P/HEE5OWLS0t9ddee80rKyt9x44dfscdd3jv3r1948aNNcoNGjQo\nfkZGouXLl/uOHTt869atfuedd3r//v29srLS3d137NjhK1ascHf3NWvWeCwW85/+9KfxZT/++GP/\n6quvfM+ePf788897r169fNWqVfH5S5cu9V27dvnmzZv96quv9lNOOSU+b+PGjfH34N133/WhQ4f6\ngw8+GJ8/YsQIv+qqq3z79u2+bds2nzx5co3l3Vs5UQOHAKurkzPwOHBxknJJAxGJsqjutyNHjvSp\nU6fWmf7EE0/4wQcf7Hv27Gm2ddWXqN3dFy5c6IMHD/YuXbr4aaed5mvWrInPu+KKK3zy5MnuHiS5\nr3/9656Tk+MHHnign3HGGb5kyZIadf35z3/2nJwcr6ioqLOeqVOnevfu3T03N9dHjx5dI66ysrJ4\n3QcffLDfdNNNXlVVFZ//xBNP+CGHHOIHHHCAf+Mb3/CXXnqpRt3jxo3zbt26eV5enl944YW+fv36\n+LwPPvjABw0a5AcccIDn5+d7UVFRjWVLSkr8nHPO8Z49e3rPnj191KhR/tFHH9Uok81EXe9tTs3s\nEODPwDBgC/A08At3/2Otcl5fXSJRo9ucBmdx7L///lx11VV1LhKRzAwePJh169YxduxYHnjggTrz\nm3qb04zuR21mVwG3ANuABe4+MUkZJWppc5SopSU0NVHXO7itmeUB5wH9gM3Ak2Y23t3rnCeUeHQ7\nFotpCJ12rKioiLKysjrT8/LymDJlSitEJBJ9xcXFFBcXN3i5TLo+zgfOcvfLw9cTgW+7+5W1yqlF\nvRcpKChIetpZqulRpRa1tISWGOGlFDjBzDqZmQGnA6saHKmIiDRKvYna3d8EngSWAssAA+7Pclwi\nIhKqt48awN0LAR0OFhFpBbqEXEQk4pSoRdqw8ePH88wzz2R9PZWVlQwZMoQNGzZkfV1SV0ZdHyJ7\ni1SnHTaXhpy+mJ+fz44dO/jkk0/o3LkzAL/73e+YM2cOf/rTn1i+fDnLly9Pe0e9adOmMX/+fFat\nWsXNN9/MtGnTUpYtLi5mxowZLFmyhB49erB69er4vP3224/LLruM22+/nbvuuivDrZXmokQtkqCs\nrCyrpxc2pG4zY8+ePRQVFXHDDTfUmA5w//3313sHt6OOOoo777yT3/zmN/Wu74ADDuCyyy5j/Pjx\n3HrrrXXmjxs3jmHDhnHbbbex7777Zrwd0nTq+hCJsKlTp3L33XcnvZ/zCy+8wPDhw9MuP3HiRM46\n6yxycnLqXde3vvUtJkyYwBFHHJF0/qGHHkqPHj144403Mgtemo0StUiEffOb3yQWi3HnnXfWmL5t\n2zY++eQTBg0a1KLxDB48mGXLlrXoOkWJWiTyCgsL+eUvf8lXX30Vn1bdj57q5v3Zkpubm9U+fElO\niVok4o4++mjOPvtsbrvttvi0vLw8gBrDYQ0dOpTc3Fy6du3Ka6+9lpVYtmzZEl+3tBwlapE2oKCg\ngAceeIDPPvsM+McAsx988EG8zIoVK9iyZQvl5eWcfPLJWYlj1apVNQa6lZahRC3SBgwYMICxY8dy\nzz33xKeNHj2axYsXp11u9+7d7Nixg6qqKnbt2sXOnTvjI3WvWbOGDh06UFpaCgSDiOzcuZPKykqq\nqqrYuXMnu3btite1bt06Nm3axAknnJCFLZR0dHqeSIK8vLysnp7XkG6D6tPwqk2bNo05c+bEp//w\nhz9k7NixXH/99SnruPzyy3n44Yfjy9x6663MmjWLiy++mNLSUvLz8zn00EMBePnllznttNPiZbt0\n6cLw4cNZtGgRAI8++iiXXHKJTs1rBUrUIgmidC/txAtOIBgRe9u2bfHXRx99NMOGDeOZZ57h3HPP\nTVrHrFmzmDVrVtJ5L7/8MjfccAP77LMPAMOHD4+3tmurrKxk1qxZvPzyy43ZFGkiJWqRNmzOnDmN\nXvamm27KuOx+++3HypUrG70uaRr1UYuIRJwStYhIxClRi4hEXL2J2swGmtlSM1sS/t0cjkouIiIt\noN6Die7+AfANADPrAHwKPJ3luEREJNTQro8zgI/dfW02ghERkboamqjHAo9lIxAREUku4/OozWxf\n4Fwg5WVQiVd0xWIxYrFYE0KT9i7VaCoNGQVlbzd+/HguvPDClBe8NNazzz7L3LlzeewxtcuaU3Fx\nMcXFxQ1eriEXvIwC/ubu61MVyOalt9L+pBpNpTX3o6Jp0ygL732RDXl9+zJlxoyMyjZ0KK7nn3+e\n2267jRUrVtC5c2fOOecc7r777pSDBqQbpuucc87hpptuYsWKFQwdOrSJWy3VajdgCwsLM1quIYl6\nHOr2kHaurLSUgvz8rNVfUFKScdmGDsVVXl7OzTffzKmnnsrOnTsZN24c1113Hb/61a+S1l/fMF0X\nXnghv/3tb7n33nszjlmyI6M+ajPrTHAg8anshiMiiRoyFNeFF17ImWeeSadOnejWrRuXX3552vtS\n1zdMVywW4w9/+EPTN0KaLKNE7e7b3b2Xu2+pv7SINJemDMW1ePFijj766Eave8iQIaxZs4aKiopG\n1yHNQzdlEom4wsJCTjnllBoHWOsbiuull17ikUce4c0332z0enNzc3F3ysrKMhocV7JHl5CLRFym\nQ3FVe+ONN5gwYQLz5s1jwIABjV7vli1bMDMNvRUBStQibUAmQ3EBLF26lDFjxvDQQw81+fTYVatW\nkZ+fr9Z0BChRi7QBmQzFtWLFCkaNGsW9997L6NGj69RRWFjIiBEj4q/TDdMFQR/3qFGjsrRF0hDq\noxZJkNe3b4NOoWtM/Zlq6FBc//Vf/8WGDRu47LLLuPTSS4HgXOx33nkHgLVr19YY9DbdMF0Ajz32\nGI8++mgjt1SakxK1SIJML0ZpCQ0dimvmzJnMnDkzZX1Llixh4cKF8dfphul67rnn+NrXvsYxxxzT\nxK2Q5qBELdKGNWQoriVLlmRc9uyzz+bss89uTEiSBeqjFhGJOCVqEZGIU6IWEYk4JWoRkYhTohYR\niTid9SF7tX79+tU5X1mkufXr169JyytRy16tpJ6LWxIHMWiJAQ0KJk2qcz/sgpISCh56KOvrluhS\nohZJQ6MWSRSoj1pEJOIyHeGlm5n9j5mtMrN3zezb2Q5MREQCmXZ9/AJ43t3/xcw6Al2yGJOIiCSo\nN1GbWS7wHXefBODuu4G6A7iJiEhWZNKi7g9sMLNZwLHAX4Gr3X17ViMTiYCWPutDJJlMEnVH4Djg\nx+7+VzMrAq4HptcumLgjx2KxJo8wIdLaCgsL48/bSqIumjaNstLSGtPy+vaN1C1c91bFxcUUFxc3\neLlMEvWnwFp3/2v4+kngP5IVbCs7skh7VlZamvRcbGl9tRuwiQ2BdOo968PdvwDWmtnAcNLpwMqG\nhygiIo2R6VkfVwGPmtm+wGrgB9kLSUREEmWUqN19GfCtLMciIiJJ6BJykTSmT69zzFykxSlRi6Sh\nA+QSBbrXh4hIxClRi4hEnBK1iEjEKVGLiEScDiaKpKF7fUgUKFGLpNEW7/Uh7Y+6PkREIk6JWkQk\n4pSoRUQiTolaRCTidDBRJA3d60OiQIlaJA2d6SFRoK4PEZGIy6hFbWYlwGagCtjl7sdnMygREfmH\nTLs+qoCYu2/KZjAiIlJXpl0f1oCyIiLSjDJtUTvwopk5cL+7P5DFmEQiQ/f6kCjINFGf5O5/N7Ne\nwEtmtsrdX81mYCJRoHt9SBRkOrjt38O/683saeB4oE6iTtyRY7EYsVisWYKUvcuyZcuSJsW8vDym\nTJnS8gGJNJPi4mKKi4sbvFy9idrMugAd3L3CzA4AzgQKk5VVi0Oag7sn3Ze0f0lbV7sBm/iLLZ1M\nWtQHAU+H/dMdgUfdfUEjYhQRkUaoN1G7+yfAsBaIRUREktAl5CJp6F4fEgVK1CJpqF9cokAXsYiI\nRJwStYhIxClRi4hEnBK1iEjE6WCiSBq614dEgRK1SBq614dEgbo+REQiTolaRCTilKhFRCJOiVpE\nJOJ0MFEkDd3rQ6JAiVokDZ3pIVGgrg8RkYhTohYRibiME7WZdTCzJWb2TDYDEhGRmhrSor4aWJmt\nQEREJLmMDiaa2WHAaOAW4CdZjUgkQnSvD4mCTM/6+DkwFeiWxVhEIkf3+pAoqLfrw8y+B3zh7m8D\nFj5ERKSFZNKiPhk418xGA52BXDOb7e4X1y6Y2OKIxWLEYrFmClNk77Vs6VIKJk2qMz2vb1+mzJjR\nYnVI0xUXF1NcXNzg5epN1O5+I3AjgJkNB65JlqRBPw1FssG3bqUgP7/O9IKSkhatQ5qudgM2sWst\nHZ1HLSIScQ26hNzdFwOLsxSLSOToXh8SBbrXh0ga6s6TKFDXh4hIxClRi4hEnBK1iEjEKVGLiESc\nDiaKpKF7fUgUKFGLpKF7fUgUqOtDRCTilKhFRCJOiVpEJOKUqEVEIk4HE0XS0L0+JAqUqEXS0Jke\nEgXq+hARiTglahGRiFOiFhGJuHr7qM1sf+BlYL+w/JPuntn4MSIi0mSZjJm408xOc/dtZrYP8JqZ\nveDub7ZAfCKtSvf6kCjI6KwPd98WPt0/XMazFpFIhOheHxIFGfVRm1kHM1sK/B14yd3fym5YIiJS\nLdMWdRXwDTPrCsw3s6+5+8ra5RJbHLWHRZfmUVRURFlZWZ3peXl5TJkyJSt1v//++wwaNKjGtJUr\n63z8Da67oXVEXdG0aZSVltaY9v7q1Qzq379O2by+fZkyY0ZLhZbSsqVLKZg0qc70VPEl28aobEtb\nUFxcTHFxcYOXa+go5OVmVgyMBNImasmOsrKypO9zc7z3qeoeM2ZMneljxoxpct0NrSPqykpLKcjP\nrzFtzKuvUjBiRJ2yBSUlLRNUPXzr1joxQ+r4km1jVLalLajdgE3sWkun3q4PMzvQzLqFzzsDZwDv\nNSpKERFpsExa1AcDD5tZB4LE/ri7P5/dsESiQff6kCjI5PS8d4DjWiAWkchRd55Ega5MFBGJOCVq\nEZGIU6IWEYk4JWoRkYjTwAEiaeheHxIFStQiaeheHxIF6voQEYk4JWoRkYhTohYRiTglahGRiNPB\nRJE0dK8PiQIlapE0dKaHRIG6PkREIk6JWkQk4pSoRUQiTolaRCTi6j2YaGaHAbOBPsAe4AF3vyfb\ngYlEge5bplVOAAAHyElEQVT1IVGQyVkfu4GfuPvbZpYD/M3MFri7xk2Udk/3+pAoqLfrw93/7u5v\nh88rgFXAodkOTEREAg3qozazfGAY8JdsBCMiInVlfMFL2O3xJHB12LKuI/GnYSwWIxaLNTE8aWuW\nLVuWtItg5cqVWak7Ly+PKVOm1ClbVFREWVlZnenvv/8+gwYNymj6+3/+c43XBZMmAbDwlVfomZtb\np47NX34JP/xhfZsBwLKlS+P1JVq5dCnk52dUR1tVNG0aZaWlNabl9e3LlBkzWimillNcXExxcXGD\nl8soUZtZR4Ik/Yi7/z5VOfXhibsn3Q/GjBmTlbpT7XNlZWUp48h0+phhw2quK0ygi555hvkTJ9ap\n49R7Mj/G7lu3xuursc5XX824jraqrLS0zrYXlJS0SiwtrXYDNvEYSDqZtqhnAivd/RcNjkykDZs+\nfHhrhyCS0el5JwMTgHfMbCngwI3u/r/ZDk6ktRWo+04ioN5E7e6vAfu0QCwiIpKErkwUEYk4JWoR\nkYhTohYRiTgNHCCSRkHCOa86sCitRYlaJI3CxYvjz5WopbWo60NEJOKUqEVEIk6JWkQk4pSoRUQi\nTgcTRdLQvT4kCpSoRdLQmR4SBer6EBGJOCVqEZGIU6IWEYk4JWoRkYjTwUSRNHSvD4mCTEZ4+R1w\nNvCFu389+yGJRIfu9SFRkEnXxyzgrGwHIiIiydWbqN39VWBTC8QiIiJJ6GCiiEjENevBxIKCgvjz\nWCxGTH16jVZUVERZWVmd6StXrkxaftmyZTXef4C8vDymTJnS5Lqj7MXHHuPt+fPrTN9QWVnn/Ujn\ni1WrKJg0qca0z1avrvG6ODywWFlZmbSOnTt3xstUS/Y+N5dlS5fWiRlg5dKlkJ/f6nUXTZtGWWlp\nRnWkWl9e375MmTEjo7pTlY2S4uLiOvtIJrKWqKVpysrKkr6fY8aMSVre3euUT/V5NLTuKNt3+3bm\njxtXZ/qpM2c2uJ6CWsnjhT17atzro7rh4W+9lbKe2o2TquXLGxRHQ/jWrXViBhjz6quRqLustDTj\nOlKtr6CkJOO6U5WNktoN2MLCwoyWyzRRW/gQ2avoTA+Jgnr7qM1sLvA6MNDMSs3sB9kPS0REqtXb\nonb38S0RiIiIJKezPkREIk6JWkQk4nSvD5E0dK8PiQIlapE0dK8PiQJ1fYiIRJwStYhIxClRi4hE\nnBK1iEjE6WCiSBqJ9/oQaS1K1CJp6EwPiQJ1fYiIRJwStYhIxClRi4hEnBK1iEjE6WCiSBq614dE\nQUaJ2sxGAkUELfDfuft/ZjUqkYjQvT4kCjIZ4aUD8EvgLOBoYJyZDc52YFHSmMEo2xJtX9tW3AbG\nCmyK9v75ZSKTPurjgQ/dfY277wL+Gzgvu2FFS3vfUbR9bZsSdfuXSaI+FFib8PrTcJqIiLSATPqo\nk40+7s0dSEM88cQTLE7oO6x23XXX0a9fv1aISEQke8w9fc41sxOAAncfGb6+HvDaBxTNrFWTt4hI\nW+TuyRrDNWSSqPcB3gdOBz4H3gTGufuq5ghSRETSq7frw933mNmVwAL+cXqekrSISAupt0UtIiKt\nq1kvITezfzez98zsHTO7vTnrjgozu9bMqsysR2vH0pzM7A4zW2Vmb5vZPDPr2toxNZWZjQz3xw/M\n7D9aO57mZGaHmdkiM1sZft+uau2YssHMOpjZEjN7prVjaW5m1s3M/if83r1rZt9OVbbZErWZxYBz\ngKHufgxwV3PVHRVmdhhwBrCmtWPJggXA0e4+DPgQuKGV42mSveBCrd3AT9z9a8CJwI/b2fZVuxpY\n2dpBZMkvgOfdfQhwLJCyS7k5W9STgdvdfTeAu29oxrqj4ufA1NYOIhvc/Y/uXhW+fAM4rDXjaQbt\n+kItd/+7u78dPq8g+JK3q+sbwobRaODB1o6luZlZLvAdd58F4O673b08VfnmTNQDgVPN7A0z+5OZ\nfbMZ6251ZnYOsNbd32ntWFrApcALrR1EE+01F2qZWT4wDPhL60bS7KobRu3xQFp/YIOZzQq7du43\ns86pCjfo7nlm9hJwUOIkgjfxp2Fdee5+gpl9C3giDKbNqGf7bgS+W2tem5Jm+25y92fDMjcBu9x9\nbiuE2Jwid6FWNphZDvAkcHXYsm4XzOx7wBfu/nbYrdrmvm/16AgcB/zY3f9qZkXA9cD0VIUz5u7f\nTTXPzK4AngrLvRUecOvp7l81ZB2tKdX2mdlQIB9YZmZG0C3wNzM73t2/bMEQmyTd5wdgZpcQ/NQc\n0TIRZdWnQN+E14cB61oplqwws44ESfoRd/99a8fTzE4GzjWz0UBnINfMZrv7xa0cV3P5lOAX+l/D\n108CKQ94N2fXx3yCi2Iws4HAvm0pSafj7ivcvY+793f3Iwje5G+0pSRdn/BWttcB57r7ztaOpxm8\nBRxpZv3MbD/gQqC9nTkwE1jp7r9o7UCam7vf6O593b0/wWe3qB0ladz9C2BtmCshyJ0pD5o258AB\ns4CZZvYOsBNoN29qEk77+yl2L7Af8FLwo4E33P1HrRtS47X3C7XM7GRgAvCOmS0l2CdvdPf/bd3I\npAGuAh41s32B1cAPUhXUBS8iIhGnMRNFRCJOiVpEJOKUqEVEIk6JWkQk4pSoRUQiTolaRCTilKhF\nRCJOiVpEJOL+PxVtB8tras//AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f802c07b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Predictions on test set\n",
    "y_prediction = tf.squeeze(tf.round(tf.nn.sigmoid(tf.add(x_data, A))))\n",
    "correct_prediction = tf.equal(y_prediction, y_target)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "acc_value_test = sess.run(accuracy, feed_dict={x_data: [x_vals_test], y_target: [y_vals_test]})\n",
    "acc_value_train = sess.run(accuracy, feed_dict={x_data: [x_vals_train], y_target: [y_vals_train]})\n",
    "print('Accuracy on train set: ' + str(acc_value_train))\n",
    "print('Accuracy on test set: ' + str(acc_value_test))\n",
    "\n",
    "# Plot classification result\n",
    "A_result = -sess.run(A)\n",
    "bins = np.linspace(-5, 5, 50)\n",
    "plt.hist(x_vals[0:50], bins, alpha=0.5, label='N(-1,1)', color='white')\n",
    "plt.hist(x_vals[50:100], bins[0:50], alpha=0.5, label='N(2,1)', color='red')\n",
    "plt.plot((A_result, A_result), (0, 8), 'k--', linewidth=3, label='A = '+ str(np.round(A_result, 2)))\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Binary Classifier, Accuracy=' + str(np.round(acc_value_test, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "_merged"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
